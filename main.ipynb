{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alihuss1017/LSTM-Weather-Prediction/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "gh_token = userdata.get('GITHUB_TOKEN')"
      ],
      "metadata": {
        "id": "-Qm9pNHhvCDo"
      },
      "id": "-Qm9pNHhvCDo",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b5305911",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5305911",
        "outputId": "2da27eb7-9360-4b77-e7e8-b14baefcbfcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LSTM-Weather-Prediction'...\n",
            "remote: Enumerating objects: 22, done.\u001b[K\n",
            "remote: Counting objects: 100% (22/22), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 22 (delta 7), reused 5 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (22/22), 87.69 KiB | 6.75 MiB/s, done.\n",
            "Resolving deltas: 100% (7/7), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://{gh_token}@github.com/alihuss1017/LSTM-Weather-Prediction.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd LSTM-Weather-Prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNQdfW-pvlv_",
        "outputId": "f801bdfa-408e-4db2-a2c6-4819dced04f2"
      },
      "id": "CNQdfW-pvlv_",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LSTM-Weather-Prediction\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('data/seattle-weather.csv')"
      ],
      "metadata": {
        "id": "nRDvgGjyus60"
      },
      "id": "nRDvgGjyus60",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking for Null Values and Duplicates"
      ],
      "metadata": {
        "id": "zF_FV55zerD1"
      },
      "id": "zF_FV55zerD1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'''Number of null values:\\n{df.isnull().sum()}\\n\\nNumber of duplicated rows: {df.duplicated().sum()}''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hetk18syvkof",
        "outputId": "1af3f39f-4ecf-467a-865f-4348dcb41c24"
      },
      "id": "Hetk18syvkof",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of null values:\n",
            "date             0\n",
            "precipitation    0\n",
            "temp_max         0\n",
            "temp_min         0\n",
            "wind             0\n",
            "weather          0\n",
            "dtype: int64\n",
            "\n",
            "Number of duplicated rows: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting DateTime as Index"
      ],
      "metadata": {
        "id": "CHhby-2Sew1T"
      },
      "id": "CHhby-2Sew1T"
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.set_index(df[\"date\"])\n",
        "df = df.drop('date', axis = 1)\n"
      ],
      "metadata": {
        "id": "zhUei1ew3YqK"
      },
      "id": "zhUei1ew3YqK",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the mean and standard deviation for Inference Purposes"
      ],
      "metadata": {
        "id": "DHMrpQrWez0r"
      },
      "id": "DHMrpQrWez0r"
    },
    {
      "cell_type": "code",
      "source": [
        "mu, std = df['temp_max'].mean(), df['temp_max'].std()"
      ],
      "metadata": {
        "id": "oldB_62DNaYM"
      },
      "id": "oldB_62DNaYM",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One-Hot Encoding Categorical Features:"
      ],
      "metadata": {
        "id": "Wl01iQGXe7P8"
      },
      "id": "Wl01iQGXe7P8"
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns = ['weather'])"
      ],
      "metadata": {
        "id": "wkB6jb194QxD"
      },
      "id": "wkB6jb194QxD",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Z-Score Normalization on Numerical Features"
      ],
      "metadata": {
        "id": "Qg3lJagFfAk1"
      },
      "id": "Qg3lJagFfAk1"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "columns_to_normalize = df_encoded.select_dtypes(include='float').columns.tolist()\n",
        "\n",
        "df_encoded[columns_to_normalize] = scaler.fit_transform(df_encoded[columns_to_normalize])"
      ],
      "metadata": {
        "id": "uU1wBOfc46ZB"
      },
      "id": "uU1wBOfc46ZB",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the PyTorch Custom Dataset Class"
      ],
      "metadata": {
        "id": "mZFaNPSZfIOp"
      },
      "id": "mZFaNPSZfIOp"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class WeatherDataset(Dataset):\n",
        "\n",
        "  def __init__(self, data_df, seq_len):\n",
        "    self.data = data_df\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    cols_to_cast = self.data.select_dtypes(include = ['object', 'bool']).columns.tolist()\n",
        "    for col in cols_to_cast:\n",
        "      self.data[col] = self.data[col].astype('int')\n",
        "\n",
        "    x = torch.tensor(self.data.iloc[idx:idx+self.seq_len].values, dtype = torch.float32)\n",
        "    y = torch.tensor(self.data['temp_max'].iloc[idx+self.seq_len+1], dtype = torch.float32)\n",
        "\n",
        "    return x, y\n"
      ],
      "metadata": {
        "id": "6YshHC0S6gA5"
      },
      "id": "6YshHC0S6gA5",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model"
      ],
      "metadata": {
        "id": "mrpuLdAOfWOM"
      },
      "id": "mrpuLdAOfWOM"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_features = 9\n",
        "\n",
        "class lstmModel(nn.Module):\n",
        "  def __init__(self, hidden_features, num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.lstm = nn.LSTM(input_size = input_features,\n",
        "                        hidden_size = hidden_features, num_layers = num_layers,\n",
        "                        batch_first = True)\n",
        "    self.fc = nn.Linear(hidden_features, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, [h, c] = self.lstm(x)\n",
        "    return self.fc(h[-1])\n"
      ],
      "metadata": {
        "id": "BC7CNMZBNOaX"
      },
      "id": "BC7CNMZBNOaX",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Debugging"
      ],
      "metadata": {
        "id": "hgHyfzaAfYaC"
      },
      "id": "hgHyfzaAfYaC"
    },
    {
      "cell_type": "code",
      "source": [
        "model = lstmModel(32, 2)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "  print(f'Output: {model(torch.rand((5, 9)))}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "549_8RH9XUZU",
        "outputId": "18f671f4-36e2-4d21-cf34-81fe49081457"
      },
      "id": "549_8RH9XUZU",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output: tensor([0.1364])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuring Device"
      ],
      "metadata": {
        "id": "ttZ33rBlfphS"
      },
      "id": "ttZ33rBlfphS"
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "print(f'Device: {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq27kfnCZ1Li",
        "outputId": "2c8bfd49-488a-4f6e-c8c6-309f5598f758"
      },
      "id": "Iq27kfnCZ1Li",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model"
      ],
      "metadata": {
        "id": "tcX2qWfQfr3T"
      },
      "id": "tcX2qWfQfr3T"
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, loss_fn):\n",
        "  model.train()\n",
        "\n",
        "  for X, y in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    y_hat = model(X)\n",
        "\n",
        "    loss = loss_fn(y, y_hat)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "T8ERcltGYYJb"
      },
      "id": "T8ERcltGYYJb",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Model"
      ],
      "metadata": {
        "id": "Gp4aPc-Dftil"
      },
      "id": "Gp4aPc-Dftil"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def eval(model, val_loader, loss_fn):\n",
        "  predicted = []\n",
        "  actual = []\n",
        "  total_loss = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in val_loader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_hat = model(X)\n",
        "\n",
        "      loss = loss_fn(y, y_hat)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "evFQkcohcPSf"
      },
      "id": "evFQkcohcPSf",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "id": "MPhsVZs0hkzA"
      },
      "id": "MPhsVZs0hkzA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "sJPGOy27hr6X",
        "outputId": "c5ca596c-cf26-4512-9416-8508dc062ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sJPGOy27hr6X",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malihuss1017\u001b[0m (\u001b[33malihuss1017-uc-san-diego\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import wandb\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "  seq_len = trial.suggest_int('seq_len', 5, 20)\n",
        "  batch_size = trial.suggest_int('batch_size', 16, 64)\n",
        "  hidden_features = trial.suggest_int('hidden_features', 32, 128)\n",
        "  num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
        "  num_epochs = trial.suggest_int('num_epochs', 5, 10)\n",
        "  loss_fn = nn.MSELoss()\n",
        "\n",
        "  dataset = WeatherDataset(data_df = df_encoded, seq_len = seq_len)\n",
        "  train_len = int(0.7 * len(dataset))\n",
        "\n",
        "  train_data = Subset(dataset, range(train_len))\n",
        "  val_data = Subset(dataset, range(train_len, len(dataset)))\n",
        "\n",
        "  train_loader = DataLoader(train_data, batch_size = 32, num_workers = 2, drop_last = True)\n",
        "  val_loader = DataLoader(val_data, batch_size = 32, num_workers = 2, drop_last = True )\n",
        "\n",
        "  model = lstmModel(hidden_features = hidden_features, num_layers = num_layers)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    train(model, train_loader, optimizer, loss_fn)\n",
        "\n",
        "  val_loss = eval(model, val_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "lc331ci_iKcJ"
      },
      "id": "lc331ci_iKcJ",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LY_6MCeTiPpy"
      },
      "id": "LY_6MCeTiPpy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}